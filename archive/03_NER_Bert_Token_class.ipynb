{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#https://www.kaggle.com/code/statsgary/bert-for-token-classification-ner-tutorial/edit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-ner-token-classification.bin'\n",
    "bert_path = 'bert-base-uncased'\n",
    "train_path = './data/train/'\n",
    "test_path = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'MAX_LEN': 128,\n",
    "    'tokenizer': AutoTokenizer.from_pretrained(bert_path, do_lower_case=True),\n",
    "    'batch_size': 5,\n",
    "    'Epoch': 1, \n",
    "    'train_path': train_path,\n",
    "    'test_path': test_path,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'model_path': model_name,\n",
    "    'model_name': model_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAX_LEN': 128, 'tokenizer': PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), 'batch_size': 5, 'Epoch': 1, 'train_path': './data/train/', 'test_path': './data/test', 'device': 'cuda', 'model_path': 'bert-ner-token-classification.bin', 'model_name': 'bert-ner-token-classification.bin'}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the train data and combine data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Id  \\\n",
      "0  d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
      "1  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
      "2  c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29   \n",
      "3  5c9a3bc9-41ba-4574-ad71-e25c1442c8af   \n",
      "4  c754dec7-c5a3-4337-9892-c02158475064   \n",
      "\n",
      "                                           pub_title  \\\n",
      "0  The Impact of Dual Enrollment on College Degre...   \n",
      "1  Educational Attainment of High School Dropouts...   \n",
      "2  Differences in Outcomes for Female and Male St...   \n",
      "3  Stepping Stone and Option Value in a Model of ...   \n",
      "4  Parental Effort, School Resources, and Student...   \n",
      "\n",
      "                           dataset_title  \\\n",
      "0  National Education Longitudinal Study   \n",
      "1  National Education Longitudinal Study   \n",
      "2  National Education Longitudinal Study   \n",
      "3  National Education Longitudinal Study   \n",
      "4  National Education Longitudinal Study   \n",
      "\n",
      "                           dataset_label  \\\n",
      "0  National Education Longitudinal Study   \n",
      "1  National Education Longitudinal Study   \n",
      "2  National Education Longitudinal Study   \n",
      "3  National Education Longitudinal Study   \n",
      "4  National Education Longitudinal Study   \n",
      "\n",
      "                           cleaned_label  \n",
      "0  national education longitudinal study  \n",
      "1  national education longitudinal study  \n",
      "2  national education longitudinal study  \n",
      "3  national education longitudinal study  \n",
      "4  national education longitudinal study  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'label_count', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = train.groupby(['Id']).agg(label_count = ('cleaned_label', 'count'),\n",
    "                label = ('cleaned_label', '|'.join)).reset_index()\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>label_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n",
       "      <td>1</td>\n",
       "      <td>program for the international assessment of ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n",
       "      <td>1</td>\n",
       "      <td>trends in international mathematics and scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>1</td>\n",
       "      <td>agricultural resources management survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>2</td>\n",
       "      <td>adni|alzheimer s disease neuroimaging initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0010357a-6365-4e5f-b982-582e6d32c3ee</td>\n",
       "      <td>1</td>\n",
       "      <td>genome sequence of covid 19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  label_count  \\\n",
       "0  0007f880-0a9b-492d-9a58-76eb0b0e0bd7            1   \n",
       "1  0008656f-0ba2-4632-8602-3017b44c2e90            1   \n",
       "2  000e04d6-d6ef-442f-b070-4309493221ba            1   \n",
       "3  000efc17-13d8-433d-8f62-a3932fe4f3b8            2   \n",
       "4  0010357a-6365-4e5f-b982-582e6d32c3ee            1   \n",
       "\n",
       "                                               label  \n",
       "0  program for the international assessment of ad...  \n",
       "1  trends in international mathematics and scienc...  \n",
       "2           agricultural resources management survey  \n",
       "3  adni|alzheimer s disease neuroimaging initiati...  \n",
       "4                        genome sequence of covid 19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading all the JSON train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_json(df, path):\n",
    "    text_data = {}\n",
    "    for i, rec_id in tqdm(enumerate(df.Id), total=len(df.Id)):\n",
    "        location = f'{path}{rec_id}.json'\n",
    "\n",
    "        with open(location, 'r') as f:\n",
    "            text_data[rec_id] = json.load(f)\n",
    "\n",
    "    print('All JSON files read successfully!')\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14316/14316 [00:02<00:00, 4821.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All JSON files read successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_dict = read_all_json(df=train_df, path=config['train_path'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(text).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_joining(data_dict_id):\n",
    "    data_len = len(data_dict_id)\n",
    "    tmp = [data_dict_id[i]['text'] for i in range(data_len)]\n",
    "    tmp = '. '.join(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shorter_sentence(sentence, max_length=128, overlap=20):\n",
    "    sent_tokenized = sent_tokenize(sentence)\n",
    "    max_length = max_length\n",
    "    overlap = overlap\n",
    "\n",
    "    final_sentences = []\n",
    "\n",
    "    for tokenized_sent in sent_tokenized:\n",
    "        sent_tokenized_clean = clean_text(tokenized_sent)\n",
    "        sent_tokenized_clean = sent_tokenized_clean.replace('.', '').rstrip()\n",
    "\n",
    "        tok_sent = sent_tokenized_clean.split(\" \")\n",
    "\n",
    "        if len(tok_sent) < max_length:\n",
    "            final_sentences.append(sent_tokenized_clean)\n",
    "        else:\n",
    "            start = 0\n",
    "            end = len(tok_sent)\n",
    "\n",
    "            for i in range(start, end, max_length-overlap):\n",
    "                tmp = tok_sent[i:(i+max_length)]\n",
    "                final_sentences.append(\". \".join(i for i in tmp))\n",
    "    \n",
    "    return final_sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and labelling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_labels(sentence, labels_list):\n",
    "    matched_keywrds = []\n",
    "    matched_token = []\n",
    "    unmatched_kwords = []\n",
    "    label = []\n",
    "\n",
    "    tokens = make_shorter_sentence(sentence)\n",
    "\n",
    "    for tk in tokens:\n",
    "        tok_split = config['tokenizer'].tokenize(tk)\n",
    "\n",
    "        for i in range(len(tok_split)):\n",
    "            if tok_split[i: (1+len(kword))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c533d9af2e08da58f6681c911ab7a739b80a20c047f5849b1d93f19f3310bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
